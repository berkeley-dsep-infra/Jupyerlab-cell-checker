{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99821e85-2aea-4144-b9eb-d06773e55a73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T20:49:47.782919Z",
     "iopub.status.busy": "2024-11-15T20:49:47.782489Z",
     "iopub.status.idle": "2024-11-15T20:49:55.565760Z",
     "shell.execute_reply": "2024-11-15T20:49:55.564797Z",
     "shell.execute_reply.started": "2024-11-15T20:49:47.782884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.54.4-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: requests in /Users/vivianliu/opt/anaconda3/envs/jupyterlab-env/lib/python3.9/site-packages (2.32.3)\n",
      "Collecting Pillow\n",
      "  Downloading pillow-11.0.0-cp39-cp39-macosx_10_10_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/vivianliu/opt/anaconda3/envs/jupyterlab-env/lib/python3.9/site-packages (from openai) (4.6.2)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/vivianliu/opt/anaconda3/envs/jupyterlab-env/lib/python3.9/site-packages (from openai) (0.27.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.7.1-cp39-cp39-macosx_10_12_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Requirement already satisfied: sniffio in /Users/vivianliu/opt/anaconda3/envs/jupyterlab-env/lib/python3.9/site-packages (from openai) (1.3.0)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/vivianliu/opt/anaconda3/envs/jupyterlab-env/lib/python3.9/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/vivianliu/opt/anaconda3/envs/jupyterlab-env/lib/python3.9/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/vivianliu/opt/anaconda3/envs/jupyterlab-env/lib/python3.9/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/vivianliu/opt/anaconda3/envs/jupyterlab-env/lib/python3.9/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vivianliu/opt/anaconda3/envs/jupyterlab-env/lib/python3.9/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/vivianliu/opt/anaconda3/envs/jupyterlab-env/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/vivianliu/opt/anaconda3/envs/jupyterlab-env/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/vivianliu/opt/anaconda3/envs/jupyterlab-env/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.23.4-cp39-cp39-macosx_10_12_x86_64.whl.metadata (6.6 kB)\n",
      "Downloading openai-1.54.4-py3-none-any.whl (389 kB)\n",
      "Downloading pillow-11.0.0-cp39-cp39-macosx_10_10_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.7.1-cp39-cp39-macosx_10_12_x86_64.whl (292 kB)\n",
      "Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.4-cp39-cp39-macosx_10_12_x86_64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: tqdm, pydantic-core, Pillow, jiter, distro, annotated-types, pydantic, openai\n",
      "Successfully installed Pillow-11.0.0 annotated-types-0.7.0 distro-1.9.0 jiter-0.7.1 openai-1.54.4 pydantic-2.9.2 pydantic-core-2.23.4 tqdm-4.67.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai requests Pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9501b2a-3fdd-4d93-b625-afcd86a386b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Replace with your OpenAI API key\n",
    "openai.api_key = 'your_openai_api_key'\n",
    "\n",
    "def get_image_caption(image_url):\n",
    "    \"\"\"\n",
    "    Use CLIP model (or another method) to generate a description for the image.\n",
    "    \"\"\"\n",
    "    # Fetch the image from the URL\n",
    "    response = requests.get(image_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "\n",
    "    # Placeholder caption (replace with CLIP or any captioning model logic)\n",
    "    caption = \"A placeholder description of the image.\"\n",
    "\n",
    "    # Alternatively, use an API for image captioning (such as Google Cloud Vision API, etc.)\n",
    "    # For example: Use CLIP or another model to generate a description.\n",
    "\n",
    "    return caption\n",
    "\n",
    "def refine_caption_with_chatgpt(caption):\n",
    "    \"\"\"\n",
    "    Use OpenAI's GPT to refine and generate an alternative text description.\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"gpt-3.5-turbo\",  # Choose the model you'd like to use (e.g., gpt-4)\n",
    "        prompt=f\"Generate an accessible alternative text for the following image description: {caption}\",\n",
    "        max_tokens=100\n",
    "    )\n",
    "    \n",
    "    refined_text = response.choices[0].text.strip()\n",
    "    return refined_text\n",
    "\n",
    "# Example URL of the image (you can use file upload functionality in JupyterLab for local images)\n",
    "image_url = 'https://example.com/image.jpg'\n",
    "\n",
    "# Step 1: Get caption using image captioning model (e.g., CLIP or another API)\n",
    "caption = get_image_caption(image_url)\n",
    "\n",
    "# Step 2: Refine the caption using GPT\n",
    "refined_text = refine_caption_with_chatgpt(caption)\n",
    "\n",
    "# Output the refined alternative text\n",
    "print(f\"Generated Alternative Text: {refined_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
